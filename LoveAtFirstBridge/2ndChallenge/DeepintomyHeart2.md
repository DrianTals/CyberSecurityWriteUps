# Love at First Breach 2nd Challenge: Deep Into my Heart

## Step 2: What is Robots.txt?
- A robots.txt file is a plain text file placed in a website's root directory that instructs search engine crawlers (like Googlebot) which pages or sections of a site should not be accessed or indexed. It acts as a safety mechanism to prevent crawling of private, irrelevant, or duplicate content. 

- Purpose: Primarily used to manage web crawler traffic to avoid overloading a server, rather than to hide pages from search results.
- Location: Must reside in the root directory (e.g., example.com/robots.txt).
- Structure: It uses a "User-agent" to specify the bot (e.g., * for all) and "Disallow" or "Allow" rules.
---
[**Next**](DeepintomyHeart3.md)